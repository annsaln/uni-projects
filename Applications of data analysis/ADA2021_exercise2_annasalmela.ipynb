{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xaEagGEOv_TB"
   },
   "source": [
    "# Exercise 2 | TKO_2096 Application of Data Analysis 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ahXr1u2v_TD"
   },
   "source": [
    "#### Prediction of the metal ion content from multi-parameter data <br>\n",
    "- Use K-Nearest Neighbor Regression with euclidean distance to predict total metal concentration (c_total), concentration of Cadmium (Cd) and concentration of Lead (Pb), for each sample using number of neighbors k = 3.<br> <br>\n",
    "\n",
    "    - You may use Nearest Neighbor Regression from https://scikit-learn.org/stable/modules/neighbors.html\n",
    "    - The data should be standarized using z-score.\n",
    "    - Implement your own Leave-One-Out cross-validation and calculate the C-index for each output (c_total, Cd, Pb). \n",
    "    - Implement your own Leave-Replicas-Out cross-validation and calculate the C-index for each output (c_total, Cd, Pb).\n",
    "    - Return your solution as a Jupyter Notebook file (include your full name in the file name).\n",
    "    - Submit to moodle your solution on ** Wednesday 10 of February** at the latest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JD4rkoN9v_TF"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "o7jGr3bev_TG"
   },
   "outputs": [],
   "source": [
    "#In this cell import all libraries you need. For example: \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import shuffle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=np.VisibleDeprecationWarning)\n",
    "# for comparing the result of c-index, commented out for pdf\n",
    "#!pip install lifelines\n",
    "#from lifelines.utils import concordance_index as c_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gr08mqLUv_TI"
   },
   "source": [
    "## Read and visualize the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "H1308gVtv_TK",
    "outputId": "d8ce34a5-5a06-4ced-bb0a-c7aa21e514db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(225, 6)\n",
      "   c_total     Cd      Pb    Mod1  Mod2    Mod3\n",
      "0     2000  800.0  1200.0  126430  2604    6996\n",
      "1       35   14.0    21.0   20597   271  138677\n",
      "2       35   14.0    21.0   24566   269  161573\n",
      "3       35   35.0     0.0  105732   971  132590\n",
      "4      100   20.0    80.0   57774  5416   93798\n"
     ]
    }
   ],
   "source": [
    "#In this cell read the file Water_data.csv\n",
    "#Print the dataset dimesions (i.e. number of rows and columns)\n",
    "#Print the first 5 rows of the dataset\n",
    "\n",
    "df = pd.read_csv('Water_data.csv')\n",
    "print(df.shape)\n",
    "print(df[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzQj3Hlkv_TO"
   },
   "source": [
    "#### To show understanding of the data, answer the following questions:\n",
    "- How many different mixtures of Cadmium (Cd) and Lead (Pb) were measured? <br>\n",
    "- How many total concentrations (c_total) were measured? <br>\n",
    "- How many mixtures have less than 4 replicas? <br>\n",
    "- How many mixtures have 4 or more replicas? Print out c_total, Cd and Pb for those concentrations.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hmzyH-Hjv_TQ",
    "outputId": "c21e7186-2edc-495b-d978-1416dd657a43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67 different mixtures of Cadmium and Lead\n",
      "225 total number of concentrations\n",
      "12 different concentrations\n",
      "43 mixtures with less than 4 replicas\n",
      "24 mixtures with 4 or more replicas\n",
      "    c_total     Cd     Pb  replicas\n",
      "19       50    0.0   50.0         4\n",
      "20       50   10.0   40.0         4\n",
      "21       50   20.0   30.0         4\n",
      "22       50   30.0   20.0         4\n",
      "23       50   40.0   10.0         4\n",
      "24       50   50.0    0.0         4\n",
      "25       70    0.0   70.0         4\n",
      "26       70   14.0   56.0         4\n",
      "27       70   28.0   42.0         4\n",
      "28       70   42.0   28.0         4\n",
      "29       70   56.0   14.0         4\n",
      "30       70   70.0    0.0         4\n",
      "31      100    0.0  100.0         4\n",
      "32      100   20.0   80.0         4\n",
      "33      100   40.0   60.0         4\n",
      "34      100   60.0   40.0         4\n",
      "35      100   80.0   20.0         4\n",
      "36      100  100.0    0.0         4\n",
      "37      200    0.0  200.0         4\n",
      "38      200   40.0  160.0         4\n",
      "39      200   80.0  120.0         4\n",
      "40      200  120.0   80.0         4\n",
      "41      200  160.0   40.0         4\n",
      "42      200  200.0    0.0         4\n"
     ]
    }
   ],
   "source": [
    "#In this cell write the code to answer the previous questions and print the answers.\n",
    "# check the amount of unique mixtures\n",
    "print(df[['Cd', 'Pb']].drop_duplicates().shape[0], 'different mixtures of Cadmium and Lead')\n",
    "print(df.shape[0], 'total number of concentrations')\n",
    "print(df['c_total'].drop_duplicates().shape[0], 'different concentrations')\n",
    "\n",
    "# let's form a dataframe of the different mixtures and add a column to represent the amount of replicas for each\n",
    "replicas = df.groupby(df.columns[0:3].tolist()).size().reset_index().rename(columns={0:'replicas'})\n",
    "print(replicas[replicas['replicas'] < 4].shape[0], 'mixtures with less than 4 replicas')\n",
    "print(replicas[replicas['replicas'] >= 4].shape[0], 'mixtures with 4 or more replicas')\n",
    "print(replicas[replicas['replicas'] >= 4])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-WYn-qQXv_TR"
   },
   "source": [
    "## Standardization of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "1-JzqB_Yv_TT",
    "outputId": "bc2f6ea1-af48-4496-8165-6d801e7cebf9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   c_total     Cd      Pb      Mod1      Mod2      Mod3\n",
      "0     2000  800.0  1200.0  0.166135 -0.507624 -1.495707\n",
      "1       35   14.0    21.0 -0.890630 -0.700080  0.684335\n",
      "2       35   14.0    21.0 -0.850999 -0.700245  1.063389\n",
      "3       35   35.0     0.0 -0.040539 -0.642335  0.583562\n",
      "4      100   20.0    80.0 -0.519410 -0.275654 -0.058658\n"
     ]
    }
   ],
   "source": [
    "#Standardize the dataset features by removing the mean and scaling to unit variance. \n",
    "#In other words, use z-score to scale the dataset features (Mod1, Mod2, Mod3) \n",
    "#Print the 5 first samples (i.e. rows) of the scaled dataset\n",
    "\n",
    "df_std = df.copy()\n",
    "for column in df_std.columns[3:]:\n",
    "    df_std[column] = (df_std[column] - df_std[column].mean()) / df_std[column].std()\n",
    "print(df_std[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xXeBf6TBv_TV"
   },
   "source": [
    "## C-index code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "BGazClblv_TV"
   },
   "outputs": [],
   "source": [
    "def cindex(true_labels, pred_labels):\n",
    "    \"\"\"Returns C-index between true labels and predicted labels\n",
    "    \"\"\"  \n",
    "    n = 0\n",
    "    pairs = 0\n",
    "    for i in range(len(pred_labels)):\n",
    "        for j in range(i+1,len(pred_labels)): # start from i+1 to exclude already visited values\n",
    "            if true_labels[i] != true_labels[j]: # if pairs are comparable (not equal), add to pairs\n",
    "                pairs += 1\n",
    "            if (pred_labels[i] < pred_labels[j] and true_labels[i] < true_labels[j]) or (pred_labels[i] > pred_labels[j] and true_labels[i] > true_labels[j]):\n",
    "                n = n+1\n",
    "            if pred_labels[i] == pred_labels[j]:\n",
    "                n = n+0.5\n",
    "    cindx = n / pairs\n",
    "    return cindx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OdQNDMSzv_TV",
    "outputId": "79b07740-0778-4a92-d5a4-ac3643003b53"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.75\n"
     ]
    }
   ],
   "source": [
    "#test cindex function with following values\n",
    "#from lifelines.utils import concordance_index as c_index\n",
    "true_labels = [-1, 1, 1, -1, 1]\n",
    "predictions = [0.60, 0.80, 0.75, 0.75, 0.70]\n",
    "cindx = cindex(true_labels, predictions)\n",
    "print(cindx)\n",
    "# comparison\n",
    "#print(c_index(true_labels, predictions)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjjSn9i_v_TW"
   },
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "107KaaMKv_TW"
   },
   "outputs": [],
   "source": [
    "#Include here all the functions that you need to run in the data analysis part.\n",
    "\n",
    "def split_data(df): # split data into folds with replicas\n",
    "# a nice spaghetti implementation\n",
    "    df_copy = df.sort_values(by=['c_total', 'Cd', 'Pb']) # sort the dataframe so that the replicas follow each other\n",
    "    X = df_copy[['Mod1', 'Mod2', 'Mod3']].values.tolist()\n",
    "    y = df_copy[['c_total', 'Cd', 'Pb']].values.tolist()\n",
    "    X_folds = []\n",
    "    y_folds = []\n",
    "    i = 0\n",
    "    while len(X_folds) < 67: #we know that there are 67 unique mixtures, so the amount of folds is 67\n",
    "        X_fold = [X[i]]\n",
    "        y_fold = [y[i]]\n",
    "        for j in range(i+1,len(X)): # skip comparing the row with itself\n",
    "            if y[i][0]== y[j][0] and y[i][1] == y[j][1] and y[i][2] == y[j][2]:\n",
    "                X_fold.append(X[j]) # if the values are the same in both rows, append to fold\n",
    "                y_fold.append(y[j])\n",
    "            else:\n",
    "                break # since the arrays are sorted, whenever we meet a different value, break the loop\n",
    "        X_folds.append(X_fold) # append the fold made in the inner loop to the folds\n",
    "        y_folds.append(y_fold)\n",
    "        i = j # the next fold starts where the previous ended\n",
    "    X_folds, y_folds = shuffle(X_folds, y_folds) # shuffle just in case\n",
    "    X_folds = np.asarray(X_folds, dtype=object)\n",
    "    y_fold = np.asarray(y_folds, dtype=object)\n",
    "    return X_folds, y_folds # returns folds\n",
    "\n",
    "def loo(df): # leave-one-out CV function\n",
    "    X = df[['Mod1', 'Mod2', 'Mod3']].values\n",
    "    y = df[['c_total', 'Cd', 'Pb']].values\n",
    "    X, y = shuffle(X, y) # this might not be necessary, let's do it anyways\n",
    "    true = []\n",
    "    preds = []\n",
    "    for i in range(len(X)):\n",
    "        X_test = X[i].reshape(1, -1) # take the ith sample as a test set and delete it from the rest -> train\n",
    "        X_train = np.delete(X,i, 0)\n",
    "        y_test = y[i].reshape(1, -1)\n",
    "        y_train = np.delete(y,i, 0)\n",
    "        knn = KNeighborsRegressor(n_neighbors=3, metric='euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        pred = knn.predict(X_test)\n",
    "        preds.extend(pred)\n",
    "        true.extend(y_test)\n",
    "    preds = np.array(preds)\n",
    "    true = np.array(true)\n",
    "    print(\"C-index for c_total:\", cindex(true[:,0],preds[:,0]))\n",
    "    print(\"C-index for Cd:\", cindex(true[:,1],preds[:,1]))\n",
    "    print(\"C-index for Pb:\", cindex(true[:,2],preds[:,2]))\n",
    "\n",
    "    \n",
    "def leave_replicas_out(df): # leave-replicas-out CV function\n",
    "    true = []\n",
    "    preds = []\n",
    "    cindexs = []\n",
    "    X_folds, y_folds = split_data(df) # splitting the data into folds\n",
    "    for i in range(len(X_folds)):\n",
    "        X_test = X_folds[i] # take the ith fold as a test fold and delete it from the rest -> train\n",
    "        y_test = y_folds[i]\n",
    "        X_train = np.delete(X_folds, i, 0)\n",
    "        y_train = np.delete(y_folds, i, 0)\n",
    "        X_train = np.concatenate([x for x in X_train]) # concatenate into 2D array to evaluate\n",
    "        y_train = np.concatenate([y for y in y_train])\n",
    "        knn = KNeighborsRegressor(n_neighbors=3, metric='euclidean')\n",
    "        knn.fit(X_train, y_train)\n",
    "        pred = knn.predict(X_test)\n",
    "        true.extend(y_folds[i])\n",
    "        preds.extend(pred) # add the predictions and true values to an array\n",
    "    true = np.array(true)\n",
    "    preds = np.array(preds)\n",
    "    #not sure if the c-index should've been calculated and averaged fold-wise, here it's for each prediction\n",
    "    print(\"C-index for c_total:\",cindex(true[:,0],preds[:,0]))\n",
    "    print(\"C-index for Cb:\",cindex(true[:,1],preds[:,1]))\n",
    "    print(\"C-index for Pb:\",cindex(true[:,2],preds[:,2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ijsrhbfqv_TW"
   },
   "source": [
    "## Results for Leave-One-Out cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Gp-xd0drv_TX",
    "outputId": "4ba9a0b4-a457-4e81-a6b1-b2b69d310d8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-index for c_total: 0.9298931456867344\n",
      "C-index for Cd: 0.9046227084812294\n",
      "C-index for Pb: 0.8786069236230007\n"
     ]
    }
   ],
   "source": [
    "#In this cell run your code for leave-One-Out cross-validation and print the corresponding results.\n",
    "loo(df_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yVVb8WjLv_TX"
   },
   "source": [
    "## Results for Leave-Replicas-Out cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "XWzZdNntv_TY",
    "outputId": "22a03614-794c-4882-a1fc-235ed6e23d8c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C-index for c_total: 0.8283381113717314\n",
      "C-index for Cb: 0.7649183613813839\n",
      "C-index for Pb: 0.7716415417380048\n"
     ]
    }
   ],
   "source": [
    "#In this cell run your script for leave-Replicas-Out cross-validation and print the corresponding results.\n",
    "leave_replicas_out(df_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJO9f2kav_TY"
   },
   "source": [
    "## Interpretation of results\n",
    "#### Answer the following questions based on the results obtained\n",
    "- Which cross-validation approach had more optimistic results?\n",
    "- Which cross-validation generalize better on unseen data? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Fl6Be1sv_TZ"
   },
   "source": [
    "### In this cell write your answers to the questions about Interpretation of Results.\n",
    "\n",
    "The leave-one-out naturally produced more optimistic results, since the training data contains replicas of the true values.\n",
    "\n",
    "The leave-replicas-out probably generalizes better on unseen data, because it hasn't accumulated any bias towards the replicas unlike the leave-one-out.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ADA2021_exercise2_annasalmela.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
